# app.py
# Streamlit - ë¦¬ë·° ê°ì • ë¶„ì„ (ë§Œì¡±/ì¤‘ë¦½/ë¶€ì •) + í‚¤ì›Œë“œ ì‹œê°í™” + ë‹¨ì¼ ë¦¬ë·° ì˜ˆì¸¡
# - Repoì— Review.xlsx / Keyword.xlsxê°€ ìˆìœ¼ë©´ ìë™ ë¡œë“œ
# - ì—†ìœ¼ë©´ ì—…ë¡œë“œ UI í‘œì‹œ
# - Keyword.xlsx ì»¬ëŸ¼: Sentiment / Keywords (ë˜ëŠ” Keyword) ìë™ ì¸ì‹

import io
import re
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
)

# -------------------------
# ê¸°ë³¸ ì„¤ì •
# -------------------------
st.set_page_config(page_title="ë¦¬ë·° ê°ì • ë¶„ì„", layout="wide")

DEFAULT_REVIEW_PATH = Path("Review.xlsx")
DEFAULT_KEYWORD_PATH = Path("Keyword.xlsx")

# -------------------------
# ìœ í‹¸
# -------------------------
def normalize_text(s: str) -> str:
    if s is None:
        return ""
    s = str(s)
    s = s.replace("\u00a0", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s


def find_col(df: pd.DataFrame, candidates: List[str]) -> str | None:
    cols = {c.lower(): c for c in df.columns}
    for cand in candidates:
        if cand.lower() in cols:
            return cols[cand.lower()]
    return None


def load_excel_from_repo_or_upload(label: str, default_path: Path) -> pd.DataFrame | None:
    """
    Repoì— íŒŒì¼ ìˆìœ¼ë©´ ê·¸ê±¸ ì½ê³ , ì—†ìœ¼ë©´ ì—…ë¡œë“œ ìœ„ì ¯ì„ ë³´ì—¬ì¤€ë‹¤.
    """
    if default_path.exists():
        try:
            return pd.read_excel(default_path)
        except Exception as e:
            st.error(f"âŒ {default_path} ì½ê¸° ì‹¤íŒ¨: {e}")
            return None

    st.warning(f"ğŸ“Œ ë¦¬í¬ì§€í† ë¦¬ì— `{default_path.name}` íŒŒì¼ì´ ì—†ì–´ì„œ ì—…ë¡œë“œê°€ í•„ìš”í•´ìš”.")
    up = st.file_uploader(label, type=["xlsx"])
    if up is None:
        return None
    try:
        return pd.read_excel(up)
    except Exception as e:
        st.error(f"âŒ ì—…ë¡œë“œ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return None


def build_lexicon(df_kw: pd.DataFrame) -> Tuple[Dict[str, List[str]], List[str], str, str]:
    """
    Keyword.xlsxì—ì„œ ê°ì •ë³„ í‚¤ì›Œë“œ ì‚¬ì „ì„ ë§Œë“ ë‹¤.
    ì»¬ëŸ¼ ìë™ ì¸ì‹:
      - ê°ì •: Sentiment / ê°ì • / label / ë¼ë²¨
      - í‚¤ì›Œë“œ: Keywords / Keyword / í‚¤ì›Œë“œ
    """
    sentiment_col = find_col(df_kw, ["Sentiment", "sentiment", "ê°ì •", "label", "ë¼ë²¨"])
    keyword_col = find_col(df_kw, ["Keywords", "keywords", "Keyword", "keyword", "í‚¤ì›Œë“œ"])

    if sentiment_col is None or keyword_col is None:
        raise ValueError(
            f"Keyword.xlsx ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. "
            f"í˜„ì¬ ì»¬ëŸ¼: {list(df_kw.columns)} / "
            f"í•„ìš” ì˜ˆ: Sentiment(ê°ì •), Keywords(í‚¤ì›Œë“œ)"
        )

    df = df_kw[[sentiment_col, keyword_col]].copy()
    df[sentiment_col] = df[sentiment_col].astype(str).map(normalize_text)
    df[keyword_col] = df[keyword_col].astype(str).map(normalize_text)

    # Keywords ì»¬ëŸ¼ì´ "í‚¤ì›Œë“œ1,í‚¤ì›Œë“œ2,..." í˜•íƒœì¼ ìˆ˜ ìˆì–´ì„œ ë¶„í•´
    lex: Dict[str, List[str]] = {}
    for _, row in df.iterrows():
        sent = row[sentiment_col]
        kws_raw = row[keyword_col]
        if not sent or not kws_raw:
            continue

        # êµ¬ë¶„ì: ì‰¼í‘œ/ìŠ¬ë˜ì‹œ/ì„¸ë¯¸ì½œë¡ /íŒŒì´í”„ ë“± ëŒ€ì‘
        parts = re.split(r"[,\|/;]+", kws_raw)
        parts = [p.strip() for p in parts if p.strip()]
        if not parts:
            continue

        lex.setdefault(sent, [])
        lex[sent].extend(parts)

    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    for k in list(lex.keys()):
        seen = set()
        uniq = []
        for w in lex[k]:
            if w not in seen:
                seen.add(w)
                uniq.append(w)
        lex[k] = uniq

    sentiments = sorted(list(lex.keys()))
    return lex, sentiments, sentiment_col, keyword_col


def count_keyword_hits(texts: List[str], lex: Dict[str, List[str]]) -> pd.DataFrame:
    rows = []
    for sent, kws in lex.items():
        for kw in kws:
            kw = normalize_text(kw)
            if not kw:
                continue
            cnt = sum(1 for t in texts if kw in t)
            if cnt:
                rows.append((sent, kw, cnt))
    df = pd.DataFrame(rows, columns=["Sentiment", "Keyword", "Count"])
    if df.empty:
        return df
    return df.sort_values(["Sentiment", "Count"], ascending=[True, False]).reset_index(drop=True)


def plot_top_keywords(kw_hits: pd.DataFrame, top_n: int = 15):
    if kw_hits.empty:
        st.info("í‚¤ì›Œë“œ ë§¤ì¹­ ê²°ê³¼ê°€ ê±°ì˜ ì—†ì–´ìš”. Keyword.xlsxì˜ í‚¤ì›Œë“œë¥¼ ë” ëŠ˜ë¦¬ë©´ í›¨ì”¬ ì˜ ë‚˜ì™€ìš”.")
        return

    sentiments = kw_hits["Sentiment"].unique().tolist()
    preferred_order = ["ë§Œì¡±", "ê¸ì •", "ì¤‘ë¦½", "ë¶€ì •"]
    sentiments = sorted(sentiments, key=lambda x: preferred_order.index(x) if x in preferred_order else 999)

    fig, axes = plt.subplots(1, len(sentiments), figsize=(6 * len(sentiments), 4))
    if len(sentiments) == 1:
        axes = [axes]

    for ax, sent in zip(axes, sentiments):
        sub = kw_hits[kw_hits["Sentiment"] == sent].sort_values("Count", ascending=False).head(top_n)
        ax.barh(sub["Keyword"][::-1], sub["Count"][::-1])
        ax.set_title(f"{sent} í‚¤ì›Œë“œ Top {top_n}")
        ax.set_xlabel("Count")
        ax.set_ylabel("Keyword")

    plt.tight_layout()
    st.pyplot(fig)


def train_model(df_review: pd.DataFrame, text_col: str, label_col: str, test_size: float = 0.2, seed: int = 42):
    X = df_review[text_col].astype(str).map(normalize_text)
    y = df_review[label_col].astype(str).map(normalize_text)

    # ë¹ˆê°’ ì œê±°
    mask = (X != "") & (y != "")
    X = X[mask]
    y = y[mask]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=seed, stratify=y if y.nunique() > 1 else None
    )

    # âš ï¸ multi_class íŒŒë¼ë¯¸í„°ëŠ” í™˜ê²½ì— ë”°ë¼ ì—ëŸ¬ ë‚˜ì„œ ì œê±°(ë„ˆê°€ ê²ªì€ ê·¸ ì˜¤ë¥˜ ë°©ì§€)
    clf = LogisticRegression(max_iter=3000)

    model = Pipeline(
        steps=[
            ("tfidf", TfidfVectorizer(ngram_range=(1, 2), min_df=1)),
            ("clf", clf),
        ]
    )

    model.fit(X_train, y_train)
    pred = model.predict(X_test)

    metrics = {
        "accuracy": float(accuracy_score(y_test, pred)),
        "report": classification_report(y_test, pred, output_dict=False),
        "confusion": confusion_matrix(y_test, pred).tolist(),
        "labels": sorted(y.unique().tolist()),
        "test_size": len(X_test),
        "train_size": len(X_train),
    }
    return model, metrics, (X_test, y_test, pred)


# -------------------------
# UI
# -------------------------
st.title("ë¦¬ë·° ê°ì • ë¶„ì„ (ë§Œì¡± / ì¤‘ë¦½ / ë¶€ì •)")

left, right = st.columns([1, 3])

with left:
    st.header("ë°ì´í„° ë¡œë“œ")
    st.caption("Repoì— Review.xlsx, Keyword.xlsxê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì½ê³ , ì—†ìœ¼ë©´ ì—…ë¡œë“œ UIê°€ ë– ìš”.")

    df_review = load_excel_from_repo_or_upload("Review.xlsx ì—…ë¡œë“œ", DEFAULT_REVIEW_PATH)
    df_kw = load_excel_from_repo_or_upload("Keyword.xlsx ì—…ë¡œë“œ", DEFAULT_KEYWORD_PATH)

    st.divider()
    st.header("ì„¤ì •")

    test_size = st.slider("í…ŒìŠ¤íŠ¸ ë¹„ìœ¨", 0.1, 0.5, 0.2, 0.05)
    seed = st.number_input("ëœë¤ ì‹œë“œ", value=42, step=1)

with right:
    if df_review is None or df_kw is None:
        st.info("ì™¼ìª½ì—ì„œ Review.xlsx / Keyword.xlsxë¥¼ ì¤€ë¹„í•˜ë©´ ì—¬ê¸°ì„œ ë¶„ì„ì´ ì§„í–‰ë¼ìš”.")
        st.stop()

    st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    c1, c2 = st.columns(2)
    with c1:
        st.caption("Review.xlsx (ìƒìœ„ 10ê°œ)")
        st.dataframe(df_review.head(10), use_container_width=True)
    with c2:
        st.caption("Keyword.xlsx (ìƒìœ„ 10ê°œ)")
        st.dataframe(df_kw.head(10), use_container_width=True)

    # Review ì»¬ëŸ¼ ìë™ ì¶”ì •
    text_col_guess = find_col(df_review, ["Review", "review", "ë¦¬ë·°", "text", "í…ìŠ¤íŠ¸", "ë‚´ìš©"])
    label_col_guess = find_col(df_review, ["Sentiment", "sentiment", "ê°ì •", "label", "ë¼ë²¨"])

    st.divider()
    st.subheader("ì»¬ëŸ¼ ì„ íƒ")
    colA, colB = st.columns(2)
    with colA:
        text_col = st.selectbox("ë¦¬ë·° í…ìŠ¤íŠ¸ ì»¬ëŸ¼", options=list(df_review.columns), index=(list(df_review.columns).index(text_col_guess) if text_col_guess in df_review.columns else 0))
    with colB:
        label_col = st.selectbox("ê°ì • ë¼ë²¨ ì»¬ëŸ¼", options=list(df_review.columns), index=(list(df_review.columns).index(label_col_guess) if label_col_guess in df_review.columns else 0))

    # -------------------------
    # í‚¤ì›Œë“œ ë¶„ì„ (Keywords ì§€ì›!)
    # -------------------------
    st.divider()
    st.subheader("í‚¤ì›Œë“œ ë¶„ì„ (Keyword.xlsx ê¸°ì¤€)")

    try:
        sent_lex, sentiments_list, s_col, k_col = build_lexicon(df_kw)

        texts_all = [normalize_text(t) for t in df_review[text_col].astype(str).fillna("").tolist()]
        kw_hits = count_keyword_hits(texts_all, sent_lex)

        cc1, cc2 = st.columns(2)
        with cc1:
            st.caption("ì „ì²´ Top 30")
            if not kw_hits.empty:
                st.dataframe(kw_hits.sort_values("Count", ascending=False).head(30), use_container_width=True)
            else:
                st.write("ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ")
        with cc2:
            st.caption("ê°ì •ë³„ Top 10")
            if not kw_hits.empty:
                st.dataframe(kw_hits.groupby("Sentiment").head(10), use_container_width=True)
            else:
                st.write("ë§¤ì¹­ ê²°ê³¼ ì—†ìŒ")

        st.subheader("ê°ì •ë³„ í‚¤ì›Œë“œ ì‹œê°í™”")
        top_n = st.slider("ê·¸ë˜í”„ì— í‘œì‹œí•  í‚¤ì›Œë“œ ê°œìˆ˜(ê°ì •ë³„)", 5, 30, 15, 1)
        plot_top_keywords(kw_hits, top_n=top_n)

    except Exception as e:
        st.warning(f"í‚¤ì›Œë“œ ë¶„ì„ì„ ê±´ë„ˆë›°ì—ˆì–´ìš”. âŒ {e}")

    # -------------------------
    # ëª¨ë¸ í•™ìŠµ
    # -------------------------
    st.divider()
    st.subheader("ëª¨ë¸ í•™ìŠµ/í‰ê°€")

    if st.button("í•™ìŠµ ì‹¤í–‰"):
        with st.spinner("í•™ìŠµ ì¤‘..."):
            model, metrics, test_pack = train_model(df_review, text_col, label_col, test_size=test_size, seed=int(seed))

        st.success("âœ… í•™ìŠµ ì™„ë£Œ!")
        st.write(f"- Train: {metrics['train_size']}ê°œ / Test: {metrics['test_size']}ê°œ")
        st.write(f"- Accuracy: **{metrics['accuracy']:.4f}**")

        st.caption("ë¶„ë¥˜ ë¦¬í¬íŠ¸")
        st.code(metrics["report"])

        # -------------------------
        # ë‹¨ì¼ ë¦¬ë·° ì…ë ¥ â†’ ì˜ˆì¸¡ (ìš”ì²­ì‚¬í•­ 2ë²ˆ)
        # -------------------------
        st.divider()
        st.subheader("ë¦¬ë·° í•œ ì¤„ ì…ë ¥ â†’ ê°ì • ì˜ˆì¸¡")

        user_text = st.text_area(
            "ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ) ê¸°ì‚¬ë‹˜ì´ ë„ˆë¬´ ì¹œì ˆí•˜ê³  ì‹œê°„ë„ ì •í™•í–ˆì–´ìš”!",
            height=120,
        )

        if st.button("ì˜ˆì¸¡í•˜ê¸°"):
            txt = normalize_text(user_text)
            if not txt:
                st.warning("ë¦¬ë·° ë‚´ìš©ì„ ì…ë ¥í•´ì¤˜!")
            else:
                pred_label = model.predict([txt])[0]
                st.write(f"### ì˜ˆì¸¡ ê²°ê³¼: **{pred_label}**")

                if hasattr(model, "predict_proba"):
                    probs = model.predict_proba([txt])[0]
                    classes = model.named_steps["clf"].classes_
                    prob_df = (
                        pd.DataFrame({"label": classes, "prob": probs})
                        .sort_values("prob", ascending=False)
                        .reset_index(drop=True)
                    )
                    st.caption("ë¼ë²¨ë³„ í™•ë¥ ")
                    st.dataframe(prob_df, use_container_width=True)
                    st.bar_chart(prob_df.set_index("label")["prob"])

        st.caption("Tip: ì •í™•ë„ê°€ ë‚®ìœ¼ë©´ Review.xlsx ë¼ë²¨ í’ˆì§ˆ/ë°ì´í„° ìˆ˜ê°€ ì œì¼ í¬ê²Œ ì˜í–¥ì„ ì¤˜ìš”.")
    else:
        st.info("ìœ„ì—ì„œ ì»¬ëŸ¼ì„ ê³ ë¥¸ ë’¤, 'í•™ìŠµ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì¤˜.")
